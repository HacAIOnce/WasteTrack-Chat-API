{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dftCwDU76m5d",
        "outputId": "93acb710-7f9b-4ba3-b1d3-7c7b42f99b72"
      },
      "outputs": [],
      "source": [
        "# !gdown 1MmJtib8_P0i5kMrIyEfdgDH_Okwlr8aY #download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "G0p5Bj1Hx-io"
      },
      "outputs": [],
      "source": [
        "# Import Library\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "import random\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dropout, GlobalMaxPool1D, Bidirectional, Conv1D, MaxPooling1D, Bidirectional, GRU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Flatten, Dense, GlobalMaxPool1D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "tG5BIhNYyHdU"
      },
      "outputs": [],
      "source": [
        "with open('waste_management3.json', encoding='utf-8') as content:\n",
        "  data = json.load(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwxUoXK3zRcm",
        "outputId": "a2aa3e14-e066-497c-bc99-8b4ef34dd248"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\biman\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\biman\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\biman\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Package sentence tokenizer\n",
        "nltk.download('punkt')\n",
        "# Package lemmatization\n",
        "nltk.download('wordnet')\n",
        "# Package multilingual wordnet data\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "w-QY9K7hyLTk"
      },
      "outputs": [],
      "source": [
        "# Mendapatkan semua data ke dalam list\n",
        "tags = [] # data tag\n",
        "inputs = [] # data input atau pattern\n",
        "responses = {} # data respon\n",
        "words = [] # Data kata\n",
        "classes = [] # Data Kelas atau Tag\n",
        "documents = [] # Data Kalimat Dokumen\n",
        "ignore_words = ['?', '!'] # Mengabaikan tanda spesial karakter\n",
        "\n",
        "for intent in data['intents']:\n",
        "  responses[intent['tag']]=intent['responses']\n",
        "  for lines in intent['patterns']:\n",
        "    inputs.append(lines)\n",
        "    tags.append(intent['tag'])\n",
        "    for pattern in intent['patterns']:\n",
        "      w = nltk.word_tokenize(pattern)\n",
        "      words.extend(w)\n",
        "      documents.append((w, intent['tag']))\n",
        "      # add to our classes list\n",
        "      if intent['tag'] not in classes:\n",
        "        classes.append(intent['tag'])\n",
        "\n",
        "# Konversi data json ke dalam dataframe\n",
        "# data = pd.DataFrame({\"patterns\":inputs, \"tags\":tags})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "jGpnIAWEyP-P"
      },
      "outputs": [],
      "source": [
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(inputs, tags,test_size=0.2, random_state=42)\n",
        "\n",
        "# Konversi data ke dalam dataframe\n",
        "train_data = pd.DataFrame({\"patterns\": X_train, \"tags\": y_train})\n",
        "test_data = pd.DataFrame({\"patterns\": X_test, \"tags\": y_test})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZSRrK9dtmDo",
        "outputId": "18670a24-6c08-4a93-ef37-422a66dac2c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 189 entries, 0 to 188\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   patterns  189 non-null    object\n",
            " 1   tags      189 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 3.1+ KB\n"
          ]
        }
      ],
      "source": [
        "train_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5afUT0eBtx2p",
        "outputId": "881f56e3-2487-4dbb-8127-ba6f6206587c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48 entries, 0 to 47\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   patterns  48 non-null     object\n",
            " 1   tags      48 non-null     object\n",
            "dtypes: object(2)\n",
            "memory usage: 896.0+ bytes\n"
          ]
        }
      ],
      "source": [
        "test_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QxA3cv9_yODX",
        "outputId": "6999e601-e256-42ad-e94d-67f8fe615bca"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patterns</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Apa manfaat dari pengolahan limbah sampah?</td>\n",
              "      <td>manfaat_pengolahan_limbah_sampah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Apa itu pengolahan limbah kaca?</td>\n",
              "      <td>pengolahan_limbah_kaca</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Berikan penjelasan nilai yang dihasilkan dari ...</td>\n",
              "      <td>nilai_pengolahan_kaca</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jelaskan langkah dalam pengolahan limbah?</td>\n",
              "      <td>langkah_pengolahan_limbah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bagaimana cara menghasilkan biogas dari limbah?</td>\n",
              "      <td>pengolahan_biogas</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            patterns  \\\n",
              "0         Apa manfaat dari pengolahan limbah sampah?   \n",
              "1                    Apa itu pengolahan limbah kaca?   \n",
              "2  Berikan penjelasan nilai yang dihasilkan dari ...   \n",
              "3          jelaskan langkah dalam pengolahan limbah?   \n",
              "4    Bagaimana cara menghasilkan biogas dari limbah?   \n",
              "\n",
              "                               tags  \n",
              "0  manfaat_pengolahan_limbah_sampah  \n",
              "1            pengolahan_limbah_kaca  \n",
              "2             nilai_pengolahan_kaca  \n",
              "3         langkah_pengolahan_limbah  \n",
              "4                 pengolahan_biogas  "
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hLv2UfORyAOU",
        "outputId": "5555b289-128c-46f9-a53e-c584eb851da9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patterns</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>apa daur ulang limbah sampah itu penting? kena...</td>\n",
              "      <td>pentingnya_daur_ulang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>chatbotx</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Manfaat dari pengolahan limbah kaca apa saja?</td>\n",
              "      <td>manfaat_pengolahan_kaca</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>berikan jenis atau contoh limbah sampah yang b...</td>\n",
              "      <td>jenis_sampah_daur_ulang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pagi</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            patterns                     tags\n",
              "0  apa daur ulang limbah sampah itu penting? kena...    pentingnya_daur_ulang\n",
              "1                                           chatbotx                 greeting\n",
              "2      Manfaat dari pengolahan limbah kaca apa saja?  manfaat_pengolahan_kaca\n",
              "3  berikan jenis atau contoh limbah sampah yang b...  jenis_sampah_daur_ulang\n",
              "4                                               pagi                 greeting"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "cQeG3ZFEyRLy"
      },
      "outputs": [],
      "source": [
        "train_data['patterns'] = train_data['patterns'].apply(lambda wrd: [ltrs.lower() for ltrs in wrd if ltrs not in string.punctuation])\n",
        "train_data['patterns'] = train_data['patterns'].apply(lambda wrd: ''.join(wrd))\n",
        "test_data['patterns'] = test_data['patterns'].apply(lambda wrd: [ltrs.lower() for ltrs in wrd if ltrs not in string.punctuation])\n",
        "test_data['patterns'] = test_data['patterns'].apply(lambda wrd: ''.join(wrd))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "KtXY6PSl5j-P"
      },
      "outputs": [],
      "source": [
        "# Inisialisasi Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Fungsi untuk melakukan lemmatization pada kata-kata dalam kalimat\n",
        "def lemmatize_text(text):\n",
        "    tokens = nltk.word_tokenize(text)  # Tokenisasi kata-kata dalam kalimat\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]  # Lemmatization\n",
        "    lemmatized_text = ' '.join(lemmatized_tokens)  # Menggabungkan kembali kata-kata menjadi kalimat\n",
        "    return lemmatized_text\n",
        "\n",
        "# Contoh penggunaan fungsi lemmatize_text pada dataset\n",
        "train_data['patterns'] = train_data['patterns'].apply(lemmatize_text)\n",
        "test_data['patterns'] = test_data['patterns'].apply(lemmatize_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "Oj_OfY-Jyckg"
      },
      "outputs": [],
      "source": [
        "# Tokenize the data (Tokenisasi Data)\n",
        "tokenizer = Tokenizer(num_words=2000)\n",
        "tokenizer.fit_on_texts(train_data['patterns'])\n",
        "\n",
        "x_train = tokenizer.texts_to_sequences(train_data['patterns'])\n",
        "x_test = tokenizer.texts_to_sequences(test_data['patterns'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "lcMsfSegyisb"
      },
      "outputs": [],
      "source": [
        "# Apply padding\n",
        "max_sequence_length = max(len(seq) for seq in x_train + x_test)\n",
        "x_train = pad_sequences(x_train, maxlen=max_sequence_length)\n",
        "x_test = pad_sequences(x_test, maxlen=max_sequence_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "9DODB0svyseu"
      },
      "outputs": [],
      "source": [
        "# Combine tags from train_data and test_data\n",
        "all_tags = list(set(train_data['tags']) | set(test_data['tags']))\n",
        "\n",
        "# Encoding the outputs\n",
        "le = LabelEncoder()\n",
        "le.fit(all_tags)\n",
        "\n",
        "y_train = le.transform(train_data['tags'])\n",
        "y_test = le.transform(test_data['tags'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "pBSWgeHhyu42"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset\n",
        "train_dataset = (x_train, y_train)\n",
        "test_dataset = (x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "AQrfnYeMyw8I"
      },
      "outputs": [],
      "source": [
        "# # Creating the model\n",
        "# # Menambahkan regularisasi L2\n",
        "# regularization = regularizers.l2(0.01)\n",
        "\n",
        "# # Mengubah tingkat dropout menjadi 0.5\n",
        "# dropout_rate = 0.5\n",
        "\n",
        "# # Mendefinisikan input layer\n",
        "# i = Input(shape=(max_sequence_length,))\n",
        "\n",
        "# # Embedding layer\n",
        "# embedding_size = 100\n",
        "# x = Embedding(len(tokenizer.word_index) + 1, embedding_size)(i)\n",
        "\n",
        "# # Bidirectional LSTM layer\n",
        "# lstm_units = 32\n",
        "# x = Bidirectional(LSTM(lstm_units, return_sequences=True))(x)\n",
        "\n",
        "# # Bidirectional GRU layer\n",
        "# gru_units = 64\n",
        "# x = Bidirectional(GRU(gru_units, return_sequences=True))(x)\n",
        "\n",
        "# # Flatten layer\n",
        "# x = Flatten()(x)\n",
        "\n",
        "# # Dense layer with L2 regularization\n",
        "# dense_units = 50\n",
        "# x = Dense(dense_units, activation='relu', kernel_regularizer=regularization)(x)\n",
        "# x = Dropout(dropout_rate)(x)\n",
        "\n",
        "# # Output layer\n",
        "# num_classes = len(classes)\n",
        "# x = Dense(num_classes, activation=\"softmax\")(x)\n",
        "# model = Model(i, x)\n",
        "\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "gDiz8PXGuRWZ"
      },
      "outputs": [],
      "source": [
        "# class myCallback(tf.keras.callbacks.Callback):\n",
        "#     # Define the method that checks the accuracy at the end of each epoch\n",
        "#     def on_epoch_end(self, epoch, logs={}):\n",
        "#         if logs.get('val_accuracy') > 0.8:\n",
        "#             print(\"\\nReached 0.7 val acc so cancelling training!\")\n",
        "\n",
        "#             # Stop training once the above condition is met\n",
        "#             self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "r-DsQhQ06R3M"
      },
      "outputs": [],
      "source": [
        "# learning_rate = 0.001\n",
        "# optimizer = Adam(learning_rate=learning_rate)\n",
        "# # Instantiate the callback class\n",
        "# cb = myCallback()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "WBF2qrzFy0AR"
      },
      "outputs": [],
      "source": [
        "# # Compiling the model\n",
        "# model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "iBQDyHxZy2Ku"
      },
      "outputs": [],
      "source": [
        "# # Training the model\n",
        "# batch_size=32\n",
        "# history = model.fit(train_dataset[0], train_dataset[1], epochs=500, callbacks = [cb], validation_data=test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "F_7ARwJF1bc5"
      },
      "outputs": [],
      "source": [
        "# #diisi dengan plot hasil accuray dan loss training dan testing\n",
        "\n",
        "\n",
        "# # Plot utility\n",
        "# def plot_graphs(history, string):\n",
        "#   plt.plot(history.history[string])\n",
        "#   plt.plot(history.history['val_'+string])\n",
        "#   plt.xlabel(\"Epochs\")\n",
        "#   plt.ylabel(string)\n",
        "#   plt.legend([string, 'val_'+string])\n",
        "#   plt.show()\n",
        "\n",
        "# # Plot the accuracy\n",
        "# plot_graphs(history, \"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "RGfHnsuNz50k"
      },
      "outputs": [],
      "source": [
        "# # Membuat Input Chat\n",
        "# while True:\n",
        "#   texts_p = []\n",
        "#   prediction_input = input('👨‍🦰 Kamu : ')\n",
        "\n",
        "#   # Menghapus punktuasi dan konversi ke huruf kecil\n",
        "#   prediction_input = [letters.lower() for letters in prediction_input if letters not in string.punctuation]\n",
        "#   prediction_input = ''.join(prediction_input)\n",
        "#   texts_p.append(prediction_input)\n",
        "\n",
        "#   # Tokenisasi dan Padding\n",
        "#   prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
        "#   prediction_input = np.array(prediction_input).reshape(-1)\n",
        "#   prediction_input = pad_sequences([prediction_input],max_sequence_length)\n",
        "\n",
        "#   # Mendapatkan hasil keluaran pada model\n",
        "#   output = model.predict(prediction_input)\n",
        "#   output = output.argmax()\n",
        "\n",
        "#   # Menemukan respon sesuai data tag\n",
        "#   response_tag = le.inverse_transform([output])[0]\n",
        "#   print(\"🤖 ChatbotX :\",random.choice(responses[response_tag]))\n",
        "#   if response_tag == \"goodbye\":\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "EcbkYO1h1lvG"
      },
      "outputs": [],
      "source": [
        "#diisi dengan save model h5 dan converter tflite\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "gg8vshaHBT_i"
      },
      "outputs": [],
      "source": [
        "# # Save the model to a file\n",
        "# joblib.dump(model, 'chatbot_model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Save the model to a file\n",
        "# joblib.dump(history, 'history_model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "cw27AehiBXXs"
      },
      "outputs": [],
      "source": [
        "# Load the model from the file\n",
        "chatbot_model = joblib.load('chatbot_model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcBd0THIBYaT",
        "outputId": "711e3a96-0fd6-48de-e205-d518ab7ffb2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 16)]              0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 16, 100)           16600     \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 16, 64)           34048     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 16, 128)          49920     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50)                102450    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 50)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 37)                1887      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 204,905\n",
            "Trainable params: 204,905\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(chatbot_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhxU2_VxCeIL",
        "outputId": "9e262811-c56e-4e4c-ba86-d541aa1da9d4"
      },
      "outputs": [],
      "source": [
        "# # Membuat Input Chat\n",
        "# while True:\n",
        "#   texts_p = []\n",
        "#   prediction_input = input('👨‍🦰 Kamu : ')\n",
        "\n",
        "#   # Menghapus punktuasi dan konversi ke huruf kecil\n",
        "#   prediction_input = [letters.lower() for letters in prediction_input if letters not in string.punctuation]\n",
        "#   prediction_input = ''.join(prediction_input)\n",
        "#   texts_p.append(prediction_input)\n",
        "\n",
        "#   # Tokenisasi dan Padding\n",
        "#   prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
        "#   prediction_input = np.array(prediction_input).reshape(-1)\n",
        "#   prediction_input = pad_sequences([prediction_input],max_sequence_length)\n",
        "\n",
        "#   # Mendapatkan hasil keluaran pada model\n",
        "#   output = chatbot_model.predict(prediction_input)\n",
        "#   output = output.argmax()\n",
        "\n",
        "#   # Menemukan respon sesuai data tag\n",
        "#   response_tag = le.inverse_transform([output])[0]\n",
        "#   print(\"🤖 ChatbotX :\",random.choice(responses[response_tag]))\n",
        "#   if response_tag == \"goodbye\":\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCTItDQrIrkY",
        "outputId": "5079ef12-0be9-48a7-d179-721f90321d02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
            " * Running on http://127.0.0.1:5000\n",
            "Press CTRL+C to quit\n",
            "127.0.0.1 - - [05/Jul/2023 21:31:07] \"GET / HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Jul/2023 21:31:07] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 30ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Jul/2023 21:31:47] \"POST /chat HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Jul/2023 21:31:57] \"GET /chat HTTP/1.1\" 405 -\n",
            "127.0.0.1 - - [05/Jul/2023 21:31:57] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, render_template, request\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import random\n",
        "import string\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Define your model and tokenizer here\n",
        "# chatbot_model = 'chatbot_model'\n",
        "# tokenizer = ''\n",
        "# max_sequence_length = ''\n",
        "# le = ''\n",
        "# responses = ''\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"hey\"\n",
        "\n",
        "@app.route('/chat', methods=['POST'])\n",
        "def chat():\n",
        "    texts_p = []\n",
        "    prediction_input = request.form['message']\n",
        "\n",
        "    # Remove punctuation and convert to lowercase\n",
        "    prediction_input = [letter.lower() for letter in prediction_input if letter not in string.punctuation]\n",
        "    prediction_input = ''.join(prediction_input)\n",
        "    texts_p.append(prediction_input)\n",
        "\n",
        "    # Tokenize and pad the input\n",
        "    prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
        "    prediction_input = np.array(prediction_input).reshape(-1)\n",
        "    prediction_input = pad_sequences([prediction_input], max_sequence_length)\n",
        "\n",
        "    # Get the model's output prediction\n",
        "    output = chatbot_model.predict(prediction_input)\n",
        "    output = output.argmax()\n",
        "\n",
        "    # Find the corresponding response based on the predicted tag\n",
        "    response_tag = le.inverse_transform([output])[0]\n",
        "    response = random.choice(responses[response_tag])\n",
        "\n",
        "    return {'response': response}\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
